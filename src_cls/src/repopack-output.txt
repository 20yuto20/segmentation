================================================================
Repopack Output File
================================================================

This file was generated by Repopack on: 2024-08-05T06:54:11.211Z

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.



For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
conf/
  cifar10_abci.yaml
  cifar10.yaml
  voc.yaml
models/
  cifar_resnet.py
  resnet.py
  trivial_wide.py
  wide_resnet.py
Noneoutput_cls/
  seed111/
    voc/
      HflipRcropCutout/
        config.yaml
        img.png
scripts/
  abci/
    test.sh
  cotton/
    test.sh
setup/
  create_dataset.py
  dataset.sh
  setup_env.sh
utils/
  common.py
  suggest.py
affinity.py
aug_meta.py
augment.py
dataloader.py
main.py
randaugment.py
READE.md
set_cfg.py
test.py
train_val.py

================================================================
Repository Files
================================================================

================
File: affinity.py
================
import numpy as np
import pandas as pd
import copy

import torch
from torch.utils.data import DataLoader

from dataloader import get_composed_transform, VOCDatasetLoader
from randaugment import RandAugment
from train_val import accuracy
from utils.suggest import suggest_network



class Affinity():
    def __init__(self, cfg, device):
        self.cfg = copy.deepcopy(cfg)
        self.device = device

        # get ra space
        self.cfg.augment.ra.weight = "random"
        ra = RandAugment(cfg=self.cfg, num_ops=self.cfg.augment.ra.num_op, magnitude=self.cfg.augment.ra.magnitude)
        self.ra_space_dict = ra.weight

        # get dataloader for each transform
        self.dataloaders = {}
        self.cfg.augment.name = ["ra"]
        self.cfg.augment.ra.weight = "single"
        dataset_path = f"{self.cfg.default.dataset_dir}"+ f"{self.cfg.dataset.name}" 
        for key in self.ra_space_dict:
            self.cfg.augment.ra.single = key
            aug_trans = get_composed_transform(self.cfg, "train")
            aug_dataset = VOCDatasetLoader(dataset_path, "val", self.cfg.dataset.resized_size, aug_trans)
            aug_loader = DataLoader(
                aug_dataset,
                batch_size=self.cfg.learn.batch_size,
                num_workers=self.cfg.default.num_workers,
                shuffle=False,
                pin_memory=True,
                persistent_workers=True,
                drop_last=False,
                )

            self.dataloaders[key] = aug_loader


    # 空のdfに結果を格納して返すか，
    # すでにaffinityが入っっていたら追加
    def get_all_affinity(self, model, total_df):
        orig_val_acc = self.get_orig_val_acc(model)

        result_dict = {key: 0 for key in self.ra_space_dict.keys()}
        for key in result_dict:
            aug_val_loader = self.dataloaders[key]

            aug_val_acc = self.calc_val_acc(model, aug_val_loader)
            affinity_value = aug_val_acc / orig_val_acc
            result_dict[key] = affinity_value
            print(
                "Calc Affinity ..."
                + f"{key} \t"
                + f"Val Acc: {aug_val_acc:.6f} \t"
                + f"Affinity: {affinity_value:.6f} \t"
            )

        df = pd.DataFrame(
            np.array([list(result_dict.values())]),
            columns=list(result_dict.keys()),
            )
        total_df = pd.concat([total_df, df])
        print(df)

        return total_df
    

    def calc_val_acc(self, model, val_loader):
        model.eval()
        val_acc, n_val = 0, 0
        model.eval()
        with torch.no_grad():
            for i_batch, sample_batched in enumerate(val_loader):
                if i_batch == 1:
                    break
                data, target = sample_batched["image"].to(self.device), sample_batched["label"].to(self.device)
                output = model(data)
                val_acc += accuracy(output, target)
                n_val += target.size(0)
                
        val_acc = float(val_acc) / n_val

        return val_acc
    

    def get_orig_val_acc(self, model):
        dataset_path = f"{self.cfg.default.dataset_dir}"+ f"{self.cfg.dataset.name}" 
        orig_trans = get_composed_transform(self.cfg, "test")
        orig_dataset = VOCDatasetLoader(dataset_path, "val", self.cfg.dataset.resized_size, orig_trans)
        orig_loader = DataLoader(
            orig_dataset,
            batch_size=self.cfg.learn.batch_size,
            num_workers=self.cfg.default.num_workers,
            shuffle=False,
            pin_memory=True,
            persistent_workers=True,
            drop_last=False,
            )
        orig_val_acc = self.calc_val_acc(model, orig_loader)

        return orig_val_acc



def get_affinity_init(cfg, device):
    model = suggest_network(cfg)
    model.load_state_dict(torch.load(cfg.augment.ra.aff_model))
    model.to(device)
    affinity_path = (cfg.out_dir + "affinity.csv")
    aff = Affinity(cfg, device)
    affinity_df = pd.DataFrame()
    affinity_df = aff.get_all_affinity(model, affinity_df)
    affinity_df.to_csv(affinity_path, index=False)

================
File: aug_meta.py
================
from typing import List, Dict, Tuple, Optional
import math

import torch
from torch import Tensor, nn
import torchvision.transforms.functional as F

from augment import Cutout, solarize_add



def _apply_op(
    img: Tensor, op_name: str, magnitude: float, interpolation: F.InterpolationMode, fill: Optional[List[float]]
):
    # shear degree
    if op_name == "ShearX":
        # magnitude should be arctan(magnitude)
        # official autoaug: (1, level, 0, 0, 1, 0)
        # https://github.com/tensorflow/models/blob/dd02069717128186b88afa8d857ce57d17957f03/research/autoaugment/augmentation_transforms.py#L290
        # compared to
        # torchvision:      (1, tan(level), 0, 0, 1, 0)
        # https://github.com/pytorch/vision/blob/0c2373d0bba3499e95776e7936e207d8a1676e65/torchvision/transforms/functional.py#L976
        img = F.affine(
            img,
            angle=0.0,
            translate=[0, 0],
            scale=1.0,
            shear=[math.degrees(math.atan(magnitude)), 0.0],
            interpolation=interpolation,
            fill=fill,
            center=[0, 0],
        )
    elif op_name == "ShearY":
        # magnitude should be arctan(magnitude)
        # See above
        img = F.affine(
            img,
            angle=0.0,
            translate=[0, 0],
            scale=1.0,
            shear=[0.0, math.degrees(math.atan(magnitude))],
            interpolation=interpolation,
            fill=fill,
            center=[0, 0],
        )
    # magnitude: 0 - 14.5..
    elif op_name == "TranslateX":
        img = F.affine(
            img,
            angle=0.0,
            translate=[int(magnitude), 0],
            scale=1.0,
            interpolation=interpolation,
            shear=[0.0, 0.0],
            fill=fill,
        )
    elif op_name == "TranslateY":
        img = F.affine(
            img,
            angle=0.0,
            translate=[0, int(magnitude)],
            scale=1.0,
            interpolation=interpolation,
            shear=[0.0, 0.0],
            fill=fill,
        )
    elif op_name == "Rotate":
        img = F.rotate(img, magnitude, interpolation=interpolation, fill=fill)
    elif op_name == "Brightness":
        img = F.adjust_brightness(img, 1.0 + magnitude)
    elif op_name == "Color":
        img = F.adjust_saturation(img, 1.0 + magnitude)
    elif op_name == "Contrast":
        img = F.adjust_contrast(img, 1.0 + magnitude)
    elif op_name == "Sharpness":
        img = F.adjust_sharpness(img, 1.0 + magnitude)
    elif op_name == "Posterize":
        img = F.posterize(img, int(magnitude))
    elif op_name == "Solarize":
        img = F.solarize(img, magnitude)
    elif op_name == "AutoContrast":
        img = F.autocontrast(img)
    elif op_name == "Equalize":
        past = img
        img = F.equalize(img)
    elif op_name == "Invert":
        img = F.invert(img)
    elif op_name == "Identity":
        pass
    elif op_name == "Cutout":
        _, height, width = F.get_dimensions(img)
        cutout = Cutout(n_holes=1, img_size=height, patch_size=magnitude)
        img = cutout(img)
    elif op_name == "SolarizeAdd":
        img = solarize_add(image=img, addition=int(magnitude), threshold=128)
    elif op_name == "Hflip":
        img = F.hflip(img)
    elif op_name == "Vflip":
        img = F.vflip(img)
    
    
    else:
        raise ValueError(f"The provided operator {op_name} is not recognized.")
    return img



class DefineAugmentSpace(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        
    def _ra_augmentation_space(self, num_bins: int, image_size: Tuple[int, int]) -> Dict[str, Tuple[Tensor, bool]]:
        space_dict = {
            # op_name: (magnitudes, signed)
            "Identity": (torch.tensor([0.0]), False),
            "ShearX": (torch.linspace(0.0, 0.3, num_bins), True),
            "ShearY": (torch.linspace(0.0, 0.3, num_bins), True),
            "TranslateX": (torch.linspace(0.0, 10.0, num_bins), True),
            "TranslateY": (torch.linspace(0.0, 10.0, num_bins), True),
            "Rotate": (torch.linspace(0.0, 30.0, num_bins), True),
            "Brightness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Color": (torch.linspace(0.1, 1.9, num_bins), True),
            "Contrast": (torch.linspace(0.1, 1.9, num_bins), True),
            "Sharpness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Posterize": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 4)).round().int(), False),
            "Solarize": (torch.linspace(255.0, 0.0, num_bins), False),
            "AutoContrast": (torch.tensor([0.0]), False),
            "Equalize": (torch.tensor([0.0]), False),
        }
        if image_size[0] > 100:
            space_dict["TranslateX"] = (torch.linspace(0.0, 100.0, num_bins), True)
            space_dict["TranslateY"] = space_dict["TranslateX"]

        return space_dict


    def _ra_wide_augmentation_space(self, num_bins: int, image_size: Tuple[int, int]) -> Dict[str, Tuple[Tensor, bool]]:
        return {
            # op_name: (magnitudes, signed)
            "Identity": (torch.tensor([0.0]), False),
            "ShearX": (torch.linspace(0.0, 0.99, num_bins), True),
            "ShearY": (torch.linspace(0.0, 0.99, num_bins), True),
            "TranslateX": (torch.linspace(0.0, 32.0, num_bins), True),
            "TranslateY": (torch.linspace(0.0, 32.0, num_bins), True),
            "Rotate": (torch.linspace(0.0, 135.0, num_bins), True),
            "Brightness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Color": (torch.linspace(0.1, 1.9, num_bins), True),
            "Contrast": (torch.linspace(0.1, 1.9, num_bins), True),
            "Sharpness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Posterize": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 6)).round().int(), False),
            "Solarize": (torch.linspace(255.0, 0.0, num_bins), False),
            "AutoContrast": (torch.tensor([0.0]), False),
            "Equalize": (torch.tensor([0.0]), False),
        }

    def _original_augmentation_space(self, num_bins: int, image_size: Tuple[int, int]) -> Dict[str, Tuple[Tensor, bool]]:
        space_dict = {
            # op_name: (magnitudes, signed)
            "Identity": (torch.tensor([0.0]), False),
            "ShearX": (torch.linspace(0.0, 0.3, num_bins), True),
            "ShearY": (torch.linspace(0.0, 0.3, num_bins), True),
            "TranslateX": (torch.linspace(0.0, 10, num_bins), True),
            "TranslateY": (torch.linspace(0.0, 10, num_bins), True),
            "Rotate": (torch.linspace(0.0, 30.0, num_bins), True),
            "Brightness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Color": (torch.linspace(0.1, 1.9, num_bins), True),
            "Contrast": (torch.linspace(0.1, 1.9, num_bins), True),
            "Sharpness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Posterize": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 4)).round().int(), False),
            "Solarize": (torch.linspace(255.0, 0.0, num_bins), False),
            "AutoContrast": (torch.tensor([0.0]), False),
            "Equalize": (torch.tensor([0.0]), False),
            ###
            "Cutout": (torch.linspace(0.0, 0.5, num_bins), False),
            "SolarizeAdd": (torch.linspace(0, 110.0, num_bins), False),
            "Invert": (torch.tensor([0.0]), False),
            ###
            "Hflip":(torch.tensor([0.0]), False),
            "Vflip":(torch.tensor([0.0]), False),
        }
        
        return space_dict

    def _jda_augmentation_space(self, num_bins: int, image_size: Tuple[int, int]) -> Dict[str, Tuple[Tensor, bool]]:
        space_dict = {
            # op_name: (magnitudes, signed)
            "Identity": (torch.tensor([0.0]), False),
            "ShearX": (torch.linspace(0.0, 0.3, num_bins), True),
            "ShearY": (torch.linspace(0.0, 0.3, num_bins), True),
            "TranslateX": (torch.linspace(0.0, 10.0, num_bins), True),
            "TranslateY": (torch.linspace(0.0, 10.0, num_bins), True),
            "Rotate": (torch.linspace(0.0, 30.0, num_bins), True),
            "Brightness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Color": (torch.linspace(0.1, 1.9, num_bins), True),
            "Contrast": (torch.linspace(0.1, 1.9, num_bins), True),
            "Sharpness": (torch.linspace(0.1, 1.9, num_bins), True),
            "Posterize": (8 - (torch.arange(num_bins) / ((num_bins - 1) / 4)).round().int(), False),
            "Solarize": (torch.linspace(255.0, 0.0, num_bins), False),
            "AutoContrast": (torch.tensor([0.0]), False),
            "Equalize": (torch.tensor([0.0]), False),
            "Invert": (torch.tensor([0.0]), False),
        }
        if image_size[0] > 100:
            space_dict["TranslateX"] = (torch.linspace(0.0, 100.0, num_bins), True)
            space_dict["TranslateY"] = space_dict["TranslateX"]

        return space_dict

================
File: augment.py
================
import glob
import os
import numpy as np
from PIL import Image
import random

import torch
from torch.utils.data import Dataset
import torchvision.transforms.functional as F

import sys

### Designed for use with PIL images (before ToTensor)


class Cutout(object):
    """Randomly mask out one or more patches from an image.

    Args:
        n_holes (int): Number of patches to cut out of each image.
        length (int): The length (in pixels) of each square patch.
    """
    def __init__(self, n_holes, img_size, patch_size):
        self.n_holes = n_holes
        self.length = img_size * patch_size
        

    def __call__(self, img):
        """
        Args:
            img (Tensor): Tensor image of size (C, H, W).
        Returns:
            Tensor: Image with n_holes of dimension length x length cut out of it.
        h = img.size(1)
        w = img.size(2)
        """
        _, h, w = F.get_dimensions(img)

        mask = np.ones((h, w), np.uint8)

        for n in range(self.n_holes):
            y = np.random.randint(h)
            x = np.random.randint(w)

            y1 = np.clip(y - self.length // 2, 0, h).astype(int)
            y2 = np.clip(y + self.length // 2, 0, h).astype(int)
            x1 = np.clip(x - self.length // 2, 0, w).astype(int)
            x2 = np.clip(x + self.length // 2, 0, w).astype(int)
            
            mask[y1: y2, x1: x2] = 0

        if torch.is_tensor(img):
            mask = torch.from_numpy(mask)      
            mask = mask.expand_as(img)

        else:
            mask = mask[:,:,np.newaxis]
            mask = np.tile(mask, 3)
 
        img = img * mask

        return Image.fromarray(img)
    

# Apply gaussian noise patch
class PatchGaussian(object):
    def __init__(self, patch_size, max_scale):
        self.patch_size = patch_size
        self.max_scale = max_scale

    def __call__(self, img):
        img = np.array(img)
       
        patch_size = np.array(self.patch_size)
        scale = random.uniform(0, 1) * self.max_scale
        # torch.randnはガウス分布を生成　
        gaussian = np.random.normal(loc = 0.0, scale = scale, size = img.shape) * 255

        image_plus_gaussian = np.clip((img + gaussian), 0, 255)
        # create mask and apply patch
        patch_mask = self._get_patch_mask(img, patch_size)
        #patch_mask = np.repeat(patch_mask[:,:,np.newaxis], img.shape[-1], axis=2)
        patch_mask = np.tile(patch_mask[:,:,np.newaxis], 3)
        
        # torch.where(condition, x, y)  True -> x, False -> y
        img = np.where(patch_mask, image_plus_gaussian, img)
        img = img.astype(np.uint8)
        return Image.fromarray(img)


    def _get_patch_mask(self, image, patch_size):
        image_size = image.shape[0]
    
        # randomly sample location in the image 
        x = np.random.randint(low=0, high=image_size, size=(1,))
        y = np.random.randint(low=0, high=image_size, size=(1,))
        x = x.astype(float)
        y = y.astype(float)

        startx = x - np.floor(patch_size / 2)
        starty = y - np.floor(patch_size / 2)
        endx = x + np.ceil(patch_size / 2)
        endy = y + np.ceil(patch_size / 2)

        # 画像の範囲超えないように
        startx = np.maximum(startx, 0)
        starty = np.maximum(starty, 0)
        endx = np.minimum(endx, image_size)
        endy = np.minimum(endy, image_size)

        lower_pad = image_size - endy
        upper_pad = starty
        right_pad = image_size - endx
        left_pad = startx

        padding_dims = (
            ((int(upper_pad), int(lower_pad)), (int(left_pad), int(right_pad)))
        )
        # create mask
        mask = np.pad(np.zeros((int(endy - starty), int(endx - startx))), padding_dims, constant_values=1)
        
        # Gaussian PatchすべきpatchをTrueで返す
        return mask == 0
    

# Load Dataset for Mix
class DatasetLoaderMix(Dataset):
    def __init__(self, root, phase, transform=None):
        super().__init__()
        self.transform = transform
        self.image_paths = []
        self.image_labels = []
        self.class_name = os.listdir(os.path.join(root, phase))
        self.class_name.sort()
        for i, x in enumerate(self.class_name):
            temp = sorted(glob.glob(os.path.join(root, phase, x, "*")))
            self.image_labels.extend([i] * len(temp))
            self.image_paths.extend(temp)

    def __getitem__(self, index):
        image_path = self.image_paths[index]
        image = Image.open(image_path).convert("RGB")
        if self.transform is not None:
            image = self.transform(image)
            
        return {"image": image, "label": self.image_labels[index]}

    def __len__(self):
        return len(self.image_paths)

# MixUp for ONLY img (NO label mixing), 
### NOT Effective Augmentation, just for experiment
class MixImage():
    def __init__(self, alpha, dataset_loader):
        self.alpha = alpha
        self.dataset_loader = dataset_loader
    
    def __call__(self, img):        
        if self.alpha > 0:
            lam = np.random.beta(self.alpha, self.alpha)
            
        else:
            lam = 1
        
        n_dataset = len(self.dataset_loader)
        index = random.randint(0, n_dataset - 1)
        img2 = self.dataset_loader[index]
        img2 = img2["image"]
        img = np.array(img)
        img2 = np.array(img2)
        img = lam * img + (1 - lam) * img2
        img = img.astype(np.uint8)
        
        return Image.fromarray(img)
    

def solarize_add(image, addition=0, threshold=128):
    image_array = np.array(image, dtype=np.int64)

    added_image = image_array + addition
    clipped_image = np.clip(added_image, 0, 255)

    # 指定された閾値未満のピクセル値の領域に対して加算, クリップ
    result_image = np.where(image_array < threshold, clipped_image, image_array)
    result_image = result_image.astype(np.uint8)

    return Image.fromarray(result_image)


# 
class RandomDownSize(object):
    def __init__(self, orig_size, target_size):
        self.patch_size = int(orig_size / target_size)
        self.target_size = target_size

    def __call__(self, img):
        img = np.array(img)
        mini_img = np.zeros((self.target_size, self.target_size, 3), dtype=np.uint8)

        for i in range(self.target_size):
            for j in range(self.target_size):
                start_row, start_col = i * self.patch_size, j * self.patch_size
                end_row, end_col = start_row + self.patch_size, start_col + self.patch_size
                row_idx = random.randint(start_row, end_row - 1)
                col_idx = random.randint(start_col, end_col - 1)
                mini_img[i, j] = img[row_idx, col_idx]

        return Image.fromarray(mini_img)

================
File: dataloader.py
================
import glob
import os
import random
from PIL import Image
import xml.etree.ElementTree as ET

from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import torch

from utils.common import show_img
from augment import Cutout
from randaugment import RandAugment

class VOCDatasetLoader(Dataset):
    def __init__(self, root, year, image_set, img_size, transform=None):
        super().__init__()
        self.root = root
        self.year = year
        self.image_set = image_set
        self.transform = transform
        self.img_size = img_size
        
        self.images = []
        self.labels = []
        
        self._load_dataset()
        
    def _load_dataset(self):
        image_dir = os.path.join(self.root, f'VOC{self.year}', 'JPEGImages')
        annotation_dir = os.path.join(self.root, f'VOC{self.year}', 'Annotations')
        image_set_file = os.path.join(self.root, f'VOC{self.year}', 'ImageSets', 'Main', f'{self.image_set}.txt')
        
        with open(image_set_file, 'r') as f:
            for line in f:
                image_id = line.strip()
                image_path = os.path.join(image_dir, f'{image_id}.jpg')
                annotation_path = os.path.join(annotation_dir, f'{image_id}.xml')
                
                if os.path.exists(image_path) and os.path.exists(annotation_path):
                    self.images.append(image_path)
                    self.labels.append(self._parse_annotation(annotation_path))
    
    def _parse_annotation(self, annotation_path):
        tree = ET.parse(annotation_path)
        root = tree.getroot()
        
        classes = []
        for obj in root.findall('object'):
            class_name = obj.find('name').text
            if class_name not in classes:
                classes.append(class_name)
        
        label = torch.zeros(len(self.class_to_idx))
        for cls in classes:
            label[self.class_to_idx[cls]] = 1
        
        return label

    def __getitem__(self, index):
        image_path = self.images[index]
        label = self.labels[index]
        
        image = Image.open(image_path).convert("RGB")
        resize_fn = transforms.Resize((self.img_size, self.img_size))
        image = resize_fn(image)
        if self.transform is not None:
            image = self.transform(image)
            
        return {"image": image, "label": label}

    def __len__(self):
        return len(self.images)

    @property
    def class_to_idx(self):
        return {cls: idx for idx, cls in enumerate(self.classes)}

    @property
    def classes(self):
        return ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
                'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',
                'train', 'tvmonitor']

def get_dataloader(cfg):
    def worker_init_fn(worker_id):
        random.seed(worker_id+cfg.default.seed)

    dataset_path = f"{cfg.default.dataset_dir}"

    train_transform = get_composed_transform(cfg, "train")
    test_transform = get_composed_transform(cfg, "test")

    train_dataset = VOCDatasetLoader(dataset_path, '2012', 'train', cfg.dataset.resized_size, train_transform)
    val_dataset = VOCDatasetLoader(dataset_path, '2012', 'val', cfg.dataset.resized_size, test_transform)
    test_dataset = VOCDatasetLoader(dataset_path, '2007', 'test', cfg.dataset.resized_size, test_transform)

    print("train_data: {}".format(len(train_dataset)))
    print("val_data: {}".format(len(val_dataset)))
    print("test_data: {}".format(len(test_dataset)))

    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.learn.batch_size,
        num_workers=cfg.default.num_workers,
        shuffle=True,
        pin_memory=True,
        persistent_workers=True,
        drop_last=True,
        worker_init_fn=worker_init_fn,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.learn.batch_size,
        num_workers=cfg.default.num_workers,
        shuffle=False,
        pin_memory=True,
        persistent_workers=True,
        drop_last=False,
        worker_init_fn=worker_init_fn,
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=cfg.learn.batch_size,
        num_workers=cfg.default.num_workers,
        shuffle=False,
        pin_memory=True,
        persistent_workers=True,
        drop_last=False,
        worker_init_fn=worker_init_fn,
    )

    if cfg.save.img:
        show_img(cfg, train_loader)
    
    return train_loader, val_loader, test_loader

 
def get_composed_transform(cfg, phase):
    transform_list = []

    if phase == "train":

        for aug_name in cfg.augment.name:
            if aug_name == "rcrop":
                transform_list.append(
                    transforms.RandomCrop(size=cfg.dataset.resized_size, padding=cfg.augment.hp.rcrop_pad)
                )

            elif aug_name == "hflip":
                transform_list.append(
                    transforms.RandomHorizontalFlip(p=0.5)
                )

            elif aug_name == "cutout":
                transform_list.append(
                    transforms.RandomApply(
                        [Cutout(n_holes=1, img_size=cfg.dataset.resized_size, patch_size=cfg.augment.hp.cutout_size)],
                        p=cfg.augment.hp.cutout_p
                    )
                )

            elif aug_name == "ra":
                transform_list = transform_list + [
                    transforms.RandomCrop(size=cfg.dataset.resized_size, padding=cfg.augment.hp.rcrop_pad),
                    transforms.RandomHorizontalFlip(p=0.5),
                    transforms.RandomApply(
                        [RandAugment(cfg=cfg, num_ops=cfg.augment.ra.num_op, magnitude=cfg.augment.ra.magnitude),
                        Cutout(n_holes=1, img_size=cfg.dataset.resized_size, patch_size=cfg.augment.hp.cutout_size)],
                        p=cfg.augment.hp.ra_p
                        )
                    ]
            
            elif aug_name == "nan":
                pass
                
            else:
                    raise ValueError (f"Invalid Augment ... {aug_name}")
       
    transform_list = transform_list + [
        transforms.ToTensor(),
        transforms.Normalize(cfg.dataset.mean, cfg.dataset.std)
        ]
        
    transform_list = transforms.Compose(transform_list)

    return transform_list


        
# AffinityDataset クラスを VOC 用に修正
class AffinityDataset():
    def __init__(self, cfg, name):
        self.cfg = cfg.copy()
        self.cfg.augment.dynamic=False
        self.cfg.augment.name=["rand"]
        self.cfg.augment.rand.weight="single"
        self.cfg.augment.rand.num_op=1
        self.cfg.augment.rand.single=name
        self.size=cfg.dataset.resized_size

    def dataloader(self):
        train_transform, test_transform = get_composed_transform(self.cfg)

        dataset_path = f"{self.cfg.default.dataset_dir}"+ f"{self.cfg.dataset.name}" 
        # use train_transform for val dataset
        val_dataset = VOCDatasetLoader(dataset_path, '2012', 'val', self.cfg.dataset.resized_size, train_transform)

        val_loader = DataLoader(
            val_dataset,
            batch_size=self.cfg.learn.batch_size,
            num_workers=self.cfg.default.num_workers,
            shuffle=False,
            pin_memory=True,
            persistent_workers=True,
            drop_last=False,
        )
    
        return val_loader


# 何も変換なしのval loaderとtransfromを返す
def val_loader_transform(cfg):
    cfg = cfg.copy()
    cfg.augment.dynamic=False
    train_transform, test_transform = get_composed_transform(cfg)
    print("transform")
    print(train_transform)

    dataset_path = f"{cfg.default.dataset_dir}"+ f"{cfg.dataset.name}" 
    # use train_transform for val dataset
    val_dataset = VOCDatasetLoader(dataset_path, "val", cfg.dataset.resized_size, test_transform)

    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.learn.batch_size,
        num_workers=cfg.default.num_workers,
        shuffle=False,
        pin_memory=True,
        persistent_workers=True,
        drop_last=False,
    )

    return val_loader, train_transform

================
File: main.py
================
import time
import os
import numpy as np
from omegaconf import OmegaConf
import pandas as pd
import sys

import torch

from dataloader import get_dataloader
from train_val import train, val, test
from set_cfg import setup_config, add_config
from randaugment import reset_cfg
from affinity import Affinity, get_affinity_init
from utils.suggest import (
    setup_device,
    fixed_r_seed,
    suggest_network,
    suggest_optimizer,
    suggest_scheduler,
    suggest_loss_func,
)
from utils.common import (
    plot_log, 
    plot_selected, 
    get_time,
    copy_from_sge,
    save_learner,
    lr_step
)

# 　　$ watch -n 1 nvidia-smi
#　　 pytorch omegaconf matplotlib pandas
#　
#　nohup bash /home/park/code/rand/src/scripts/rand.sh > /home/park/code/rand/comi/12051248.log 2>&1 &

# single, w_ra

print("giselle")


def main(cfg):
    # if single-pass, set cfg for init phase
    if cfg.augment.name[0] == "single" or cfg.augment.name[0] == "w_ra":
        cfg = reset_cfg(cfg, init=True)
    # set num_worker
    if cfg.default.num_workers is None:
        cfg.default.num_workers=int(os.cpu_count() / cfg.default.num_excute) 
        print(f"CPU cores ..{os.cpu_count()}, num workers ... {cfg.default.num_workers}")

    device = setup_device(cfg)
    fixed_r_seed(cfg)

    if cfg.augment.ra.aff_calc:
        get_affinity_init(cfg, device)

    
    model = suggest_network(cfg)
    model.to(device)

    train_loader, val_loader, test_loader = get_dataloader(cfg)
    optimizer = suggest_optimizer(cfg, model)
    scheduler = suggest_scheduler(cfg, optimizer)
    loss_func = suggest_loss_func()

    # if need affinity calc, prepare csv path and instance 
    if cfg.save.affinity or cfg.save.affinity_all:
        affinity_path = (cfg.out_dir + "affinity.csv")
        aff = Affinity(cfg, device)
        
    print(OmegaConf.to_yaml(cfg))
    start = time.time()
    best_acc = 1e-8
    save_file_path = cfg.out_dir + "output.csv"
    all_training_result = []
    affinity_df = pd.DataFrame()
    for epoch in range(1, cfg.learn.n_epoch + 1):
        train_loss, train_acc = train(model, device, train_loader, optimizer, loss_func)
        val_loss, val_acc, val_mAP = val(model, device, val_loader, loss_func)

        all_training_result.append([train_loss, train_acc, val_loss, val_acc, val_mAP])
        interval = time.time() - start
        interval = get_time(interval)
        print(f"Lr: {optimizer.param_groups[0]['lr']} , time: {interval['time']}")
        print(
            f"Epoch: [{epoch:03}/{cfg.learn.n_epoch:03}] \t"
            + f"train loss: {train_loss:.6f} \t"
            + f"train acc: {train_acc:.6f} \t"
            + f"val loss: {val_loss:.6f} \t"
            + f"val acc: {val_acc:.6f} \t"
        )
        sys.stdout.flush()

        # if init phase end
        if cfg.augment.ra.init_epoch is not None and epoch == cfg.augment.ra.init_epoch:
            # for single-pass calc Affinity using the model at that epoch
            affinity_df = aff.get_all_affinity(model, affinity_df)
            affinity_df.to_csv(affinity_path, index=False)
            # start main phase, change dataloader for RA
            cfg = reset_cfg(cfg, init=False)
            print("Switch to new data loader ...")
            del train_loader
            train_loader, _, _ = get_dataloader(cfg)

        # if affinity at each epoch calc
        elif cfg.save.affinity_all and epoch % 2 == 0:
        #elif cfg.save.affinity_all:
            affinity_df = aff.calculate_affinity(model, val_acc, epoch, affinity_df)
            affinity_df.to_csv(affinity_path, index=False)
        
        # save best weight
        if best_acc < val_acc:
            best_acc = val_acc
            save_learner(cfg, model, device, True)
        # save latest epoch weight
        save_learner(cfg, model, device, False)

        scheduler.step()
        # lr_step(cfg, scheduler, epoch)

    
    all_training_result = pd.DataFrame(
        np.array(all_training_result),
        columns=["train_loss", "train_acc", "val_loss", "val_acc"],
    )
    interval = time.time() - start
    interval = get_time (interval)

    test_loss, test_acc, test_mAP = test(model, device, test_loader, loss_func, cfg)
    print(
        f"time: {interval['time']} \t"
        +f"test loss: {test_loss:.6f} \t"
        +f"test acc: {test_acc:.6f} \t"
        +f"test mAP: {test_mAP:.6f} \t"
    )

    all_training_result.loc["test_acc"] = test_acc
    all_training_result.loc["test_loss"] = test_loss
    all_training_result.loc["test_mAP"] = test_mAP
    
    add_config(cfg, {"test_acc" : test_acc})
    add_config(cfg, interval)
    plot_log(cfg, all_training_result)

    if cfg.save.affinity:
        affinity_df = aff.calculate_affinity(model, val_acc, epoch, affinity_df)
        affinity_df.to_csv(affinity_path, index=False)

    # if abci move files from SGE_LOCALDIR
    if cfg.default.env == "abci":
        print("Copy csv data from SGE_LOCALDIR")
        copy_from_sge(cfg, "selected_method")
    if cfg.save.selected and os.path.exists(cfg.out_dir + f"selected_method_{cfg.augment.ra.weight}.csv"):
        plot_selected(cfg)



if __name__ == "__main__":
    cfg = setup_config()
    main(cfg)

================
File: randaugment.py
================
from typing import List, Optional
import numpy as np
import random
import pandas as pd
from omegaconf import OmegaConf
import os
from pathlib import Path

import torch
from torch import Tensor, nn
import torchvision.transforms.functional as F

from aug_meta import DefineAugmentSpace, _apply_op
from set_cfg import override_original_config


# single w_ra


# for single-pass method
def reset_cfg(cfg, init: bool):
    # set for init phase
    if init:
        if cfg.augment.ra.init_epoch is None:
            raise ValueError("error.. set num of init phase epoch")
        print(f"Set cfg for init phase, num of init phase epoch ...{cfg.augment.ra.init_epoch}")

        if cfg.augment.name[0] == "w_ra":
            cfg.augment.ra.warmup_ra = True
            print("Apply warmup RA")

        cfg.augment.name=["nan"]
        cfg.save.affinity=True

    # set for main phase
    # start RA during training
    else:
        print("Set cfg for main phase")
        cfg.augment.name=["ra"]
        cfg.augment.ra.weight="affinity"
        cfg.save.affinity=False

        if cfg.augment.ra.warmup_ra:
            print("Set for warmup RA, weight is random")
            cfg.augment.ra.weight="random"

    override_original_config(cfg)
    print(OmegaConf.to_yaml(cfg))
    return cfg




class RandAugment(torch.nn.Module):
    def __init__(
        self,
        cfg,
        num_ops: int = 2,
        magnitude: int = 9,
        num_magnitude_bins: int = 31,
        interpolation: F.InterpolationMode = F.InterpolationMode.NEAREST,
        fill: Optional[List[float]] = None,
    ) -> None:
        
        super().__init__()
        self.cfg = cfg
        self.num_ops = num_ops
        self.magnitude = magnitude
        self.num_magnitude_bins = num_magnitude_bins
        self.interpolation = interpolation
        self.fill = fill
        self.weight_type = cfg.augment.ra.weight
        self.softmax_t = cfg.augment.ra.softmax_t
        self.single = cfg.augment.ra.single

        self.space = DefineAugmentSpace()

        # weightを取得するためにRA spaceを取得，画像サイズは何でも良い
        if self.cfg.augment.ra.space == "ra":
            op_meta = self.space._ra_augmentation_space(self.num_magnitude_bins, (32, 32))
        elif self.cfg.augment.ra.space == "jda":
            op_meta = self.space._jda_augmentation_space(self.num_magnitude_bins, (32, 32))

        self.weight = {key: 0 for key in op_meta.keys()}
        if "ra" in self.cfg.augment.name:
            if self.weight_type == "affinity":
                self.metrics_value = self.get_metrics_value(self.weight)

            self.weight = self.get_weight(self.weight)
            
            # print("Weight values ...")
            # print(self.weight)
            
        # if fix Identity rate
        self.iden_rate = float(1 / len(op_meta))

        # count num of selected method
        self.count = 0
        self.count_dict = {key: 0 for key in op_meta.keys()}



    def forward(self, img: Tensor) -> Tensor:
        self.count += 1
        fill = self.fill
        channels, height, width = F.get_dimensions(img)
        if isinstance(img, Tensor):
            if isinstance(fill, (int, float)):
                fill = [float(fill)] * channels
            elif fill is not None:
                fill = [float(f) for f in fill]

        if self.cfg.augment.ra.space == "ra":
            op_meta = self.space._ra_augmentation_space(self.num_magnitude_bins, (height, width))
        elif self.cfg.augment.ra.space == "jda":
            op_meta = self.space._jda_augmentation_space(self.num_magnitude_bins, (height, width))
     
        # softmax_t is random smpled for each image
        if self.cfg.augment.ra.softmax_t == "random":
            self.cfg.augment.ra.softmax_t = np.random.rand()
            self.weight = self.get_weight(self.weight)

        # apply transform num_ops times
        for _ in range(self.num_ops):
            # sample op according to weight value
            op_index = torch.multinomial(torch.tensor(list(self.weight.values())), 1, replacement=True).item()
            op_name = list(op_meta.keys())[op_index]
            mag_range, signed = op_meta[op_name]

            if self.cfg.augment.ra.random_magnitude:
                self.magnitude = torch.randint(len(mag_range), (1,), dtype=torch.long)

            ## self.magnitudeはレベル, magnitudeは手法ごとのハイパラ
            # transformのhyper-paraにrangがあるならlevelを指定，なかったら0.0を返す
            selected_mag = (float(mag_range[self.magnitude].item()) if len(mag_range) > 1 else 0.0)
            #magnitude = float(magnitudes[self.magnitude].item()) if magnitudes.ndim > 0 else 0.0
            
            # if hyper-para can invert, invert at 50% prob
            if signed and torch.randint(2, (1,)):
                selected_mag *= -1.0

            # Affinityで重み付けしてapply probを決めるが，
            if self.weight_type == "affinity":
                # for a certain prob -> Identity
                if random.random() < self.iden_rate:
                    op_name = list(op_meta.keys())[0]
                # else, apply transform
                else:
                    img = _apply_op(img, op_name, selected_mag, interpolation=self.interpolation, fill=fill)
            else:
                img = _apply_op(img, op_name, selected_mag, interpolation=self.interpolation, fill=fill)

            # count selected transform
            self.count_dict[op_name] += 1

        # たまに保存
        if self.count % self.cfg.learn.batch_size == 0:
            if self.cfg.save.selected:
                self.save_history()

        return img
    
    def save_history(self):
        # for abci, save at SGE dir (temp)
        if self.cfg.default.env=="abci":
            sge_dir = str(Path(self.cfg.default.dataset_dir).parent)
            file_path = os.path.join(sge_dir, f"selected_method_{self.weight_type}.csv")
        else:
            file_path = self.cfg.out_dir + f"selected_method_{self.weight_type}.csv"

        df = pd.DataFrame([list(self.count_dict.values())], columns= list(self.count_dict.keys()))  

        for key in self.count_dict:
            self.count_dict[key] = 0
        
        # 既存csvに書き足す
        if os.path.exists(file_path) and self.count != 128:
            with open(file_path, 'a') as f:
                df.to_csv(f, header=False, index=False)
        # 1番初めはcsvを作成
        else:
            df.to_csv(file_path, index = False)
        

    def __repr__(self) -> str:
        s = (
            f"{self.__class__.__name__}("
            f"num_ops={self.num_ops}"
            f", magnitude={self.magnitude}"
            f", num_magnitude_bins={self.num_magnitude_bins}"
            f", interpolation={self.interpolation}"
            f", fill={self.fill}"
            f")"
        )
        return s
    

    def get_weight(self, weight):
        # original RA, select at random
        if self.weight_type == "random":
            weight_value = np.ones(len(weight))
            weight_value = weight_value / sum(weight_value)

        # selct only one method
        elif self.weight_type == "single":
            weight[self.single] = 1.0
            weight_value = np.array(list(weight.values()))

        # proposed method, weight for selection prob
        else:
            weight_value = self.metrics_value
            # not weight for iden, iden prob is fixed
            if self.cfg.augment.ra.fix_iden:
                weight_value = np.delete(weight_value, 0)
                weight_value = nn.functional.softmax(
                    torch.tensor(weight_value) / self.cfg.augment.ra.softmax_t,
                    dim=0
                    )
                weight_value = torch.cat([torch.tensor([0.0], dtype=torch.float64), weight_value])
                
            else:
                weight_value = nn.functional.softmax(
                    torch.tensor(weight_value) / self.cfg.augment.ra.softmax_t,
                    dim=0
                    )

        for i, key in enumerate(weight):
            weight[key] = weight_value[i]

        return weight
   
    # get affinity value from csv
    def get_metrics_value(self, weight):
        file_path = (self.cfg.out_dir + "affinity.csv")

        # if not exist affinity.csv in same dir
        if not os.path.exists(file_path):
            # if affinity.csv path is not directed
            if self.cfg.augment.ra.affinity_path is None:
                raise ValueError("affinity.csv path not found ...")
            else:
                file_path = self.cfg.augment.ra.affinity_path

        # load affinity value from csv
        df = pd.read_csv(file_path)
        for key in weight:
            weight[key] = df.iloc[-1][key]

        values = np.array(list(weight.values()))

        return values

================
File: set_cfg.py
================
import os
import sys

from omegaconf import OmegaConf
import datetime



def setup_config():
    args = sys.argv
    config_file_name = args[1]
    config_file_path = f"/homes/ykohata/code/devml/homes/ypark/code/seg/src_cls/src/conf/{config_file_name}.yaml"
    # config_file_path = f"/groups/gaa50073/park-yuna/share/src/conf/{config_file_name}.yaml"
    if os.path.exists(config_file_path):
        cfg = OmegaConf.load(config_file_path)
    else:
        raise "No YAML file !!!"

    # コマンドラインで受け取った引数とconfig_fileの情報をmerge
    cfg = OmegaConf.merge(cfg, OmegaConf.from_cli(args_list=args[2:]))
    file_name = get_filename(cfg)
    if "out_dir" not in cfg:
        output_dir_path = (
            f"{cfg.default.home_dir}"
            +f"{cfg.default.output_dir}/"
            + f"seed{cfg.default.seed}/"
            + f"{config_file_name}/"
            +f"{file_name}/"
        )
    else:
        output_dir_path = f"{cfg.out_dir}"

    if cfg.default.make_dir:
        print(f"MAKE DIR {output_dir_path}")
        os.makedirs(output_dir_path, exist_ok=True)

    out_dir_comp = {"out_dir": output_dir_path}
    cfg = OmegaConf.merge(cfg, out_dir_comp)

    config_name_comp = {"execute_config_name": config_file_name}
    cfg = OmegaConf.merge(cfg, config_name_comp)

    config_name_comp = {"override_cmd": args[2:]}
    cfg = OmegaConf.merge(cfg, config_name_comp)

    dt = datetime.datetime.today()
    datetime_comp = {"datetime": dt.strftime('%Y-%m-%d %H:%M:%S.%f')}
    cfg = OmegaConf.merge(cfg, datetime_comp)

    with open(output_dir_path + "config.yaml", "w") as f:
        OmegaConf.save(cfg, f)
    return cfg


def add_config(cfg, config_name_comp: dict):
    config_file_path = cfg.out_dir + "config.yaml"
    if os.path.exists(config_file_path):
        print("### Add config")
        print(config_name_comp)
        #cfg = OmegaConf.merge(cfg, config_name_comp)
        for key, value in config_name_comp.items():
            cfg[key] = value
        with open(config_file_path, "w") as f:
            OmegaConf.save(cfg, f)
        return cfg
    else:
        raise "No YAML file !!!"
    
def override_original_config(cfg):
    config_file_path = cfg.out_dir + "config.yaml"
    if os.path.exists(config_file_path):
        original_cfg = OmegaConf.load(config_file_path)
    else:
        raise ValueError(f"cfg file {config_file_path} not found") 
    OmegaConf.merge(original_cfg, cfg)
    with open(config_file_path, "w") as f:
        OmegaConf.save(cfg, f)
    print("### Override config.")


def get_filename(cfg):
    if cfg.default.add_filename is not None:
        file_name = cfg.default.add_filename
    else:
        file_name = ""
    
    
    for aug_name in cfg.augment.name:
        print(aug_name)
        if aug_name == "ra":
            file_name = f"{file_name}RA{cfg.augment.ra.num_op}"
            if cfg.augment.ra.weight == "random":
                file_name = f"{file_name}_Random"
            elif cfg.augment.ra.weight == "single":
                file_name = f"{file_name}_{cfg.augment.ra.single}"
            elif cfg.augment.ra.weight == "affinity":
                file_name = f"{file_name}_Affinity{cfg.augment.ra.softmax_t}"
            else:
                raise ValueError(f"Invalid RandAugment weight type... {cfg.augment.ra.weight}")
            
            if cfg.augment.ra.random_magnitude:
                file_name = f"{file_name}_Randmag"

            
        elif aug_name == "single":
            file_name = f"{file_name}SinglePass{cfg.augment.ra.softmax_t}_{cfg.augment.ra.init_epoch}"
            if cfg.augment.ra.random_magnitude:
                file_name = f"{file_name}_Randmag"

        elif aug_name == "w_ra":
            file_name = f"{file_name}WarmupRA{cfg.augment.ra.init_epoch}"
            if cfg.augment.ra.random_magnitude:
                file_name = f"{file_name}_Randmag"
        
        else:
            file_name = f"{file_name}{aug_name.capitalize()}"

        
    return file_name

================
File: test.py
================
import torch
import numpy
print("hello")

================
File: train_val.py
================
import torch
import torch.nn.functional as F
from tqdm import tqdm
from sklearn.metrics import average_precision_score
import numpy as np

def accuracy(output, target):
    pred = (output > 0).float()
    correct = (pred == target).float().sum()
    return correct / (target.size(0) * target.size(1))

def train(model, device, train_loader, optimizer, criterion):
    model.train()
    train_loss = 0
    train_acc = 0
    n_samples = 0
    
    for batch in tqdm(train_loader):
        data, target = batch['image'].to(device), batch['label'].to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item() * data.size(0)
        train_acc += accuracy(output, target) * data.size(0)
        n_samples += data.size(0)
    
    return train_loss / n_samples, train_acc / n_samples

def val(model, device, val_loader, criterion):
    model.eval()
    val_loss = 0
    val_acc = 0
    n_samples = 0
    
    all_outputs = []
    all_targets = []
    
    with torch.no_grad():
        for batch in tqdm(val_loader):
            data, target = batch['image'].to(device), batch['label'].to(device)
            output = model(data)
            loss = criterion(output, target)
            
            val_loss += loss.item() * data.size(0)
            val_acc += accuracy(output, target) * data.size(0)
            n_samples += data.size(0)
            
            all_outputs.append(output.cpu().numpy())
            all_targets.append(target.cpu().numpy())
    
    all_outputs = np.concatenate(all_outputs)
    all_targets = np.concatenate(all_targets)
    
    ap_scores = []
    for i in range(all_targets.shape[1]):
        ap = average_precision_score(all_targets[:, i], all_outputs[:, i])
        ap_scores.append(ap)
    
    mAP = np.mean(ap_scores)
    
    return val_loss / n_samples, val_acc / n_samples, mAP

def test(model, device, test_loader, criterion, cfg):
    model.eval()
    test_loss = 0
    test_acc = 0
    n_samples = 0
    
    all_outputs = []
    all_targets = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader):
            data, target = batch['image'].to(device), batch['label'].to(device)
            output = model(data)
            loss = criterion(output, target)
            
            test_loss += loss.item() * data.size(0)
            test_acc += accuracy(output, target) * data.size(0)
            n_samples += data.size(0)
            
            all_outputs.append(output.cpu().numpy())
            all_targets.append(target.cpu().numpy())
    
    all_outputs = np.concatenate(all_outputs)
    all_targets = np.concatenate(all_targets)
    
    ap_scores = []
    for i in range(all_targets.shape[1]):
        ap = average_precision_score(all_targets[:, i], all_outputs[:, i])
        ap_scores.append(ap)
    
    mAP = np.mean(ap_scores)
    
    return test_loss / n_samples, test_acc / n_samples, mAP

================
File: conf/cifar10.yaml
================
default:
  env: "cotton"
  seed: 1
  output_dir: "output"
  home_dir: "/homes/ykohata/code/devml/share/"
  dataset_dir: "/homes/ykohata/code/devml/share/dataset/"
  deterministic: False
  parallel: False
  device_id: 0
  num_workers: 8
  num_excute: 4
  make_dir: True
  add_filename: null


network:
  name: "resnet20"
  pretrained: "nontrained"
  dropout_rate: 0.3


learn:
  n_epoch: 250
  batch_size: 128


augment: 
  name: 
   - "base"
  hp:
    rcrop_pad: 4
    cutout_p: 0.5
    cutout_size: 0.5
    ra_p: 1.0
    
  ra:
    space: "ra"
    weight: null
    single: null
    num_op: 2
    magnitude:  14
    random_magnitude: True
    softmax_t: 0.5
    affinity_path: null
    fix_iden: True
    init_epoch: null
    warmup_ra: False
    aff_calc: False
    aff_model: null

  

dataset:
  name: "cifar10"
  n_class: 10
  img_size: 32
  resized_size: 32
  train_size: null
  mean: 
    - 0.485
    - 0.456
    - 0.406
  std: 
    - 0.229
    - 0.224
    - 0.225
  

optimizer:
  name: SGD
  scheduler:
    name: cosine
    step:
      - 60
      - 120
      - 160
    
  hp:
    lr: 0.1
    lr_min: 0.0001
    warmup_period: null
    warmup_init: 1e-5
    momentum: 0.9
    weight_decay: 5e-4
    

save:
  img: True
  plot: True
  selected: True
  affinity: False
  affinity_all: False
  interval: null

================
File: conf/cifar10_abci.yaml
================
default:
  env: "abci"
  seed: 1
  output_dir: "output"
  home_dir: "/groups/gaa50073/park-yuna/share/"
  dataset_dir: "$SGE_LOCALDIR/datasets/"
  deterministic: False
  parallel: False
  device_id: 0
  num_workers: 8
  num_excute: 4
  make_dir: True
  add_filename: null


network:
  name: "resnet20"
  pretrained: "nontrained"
  dropout_rate: 0.3


learn:
  n_epoch: 250
  batch_size: 128


augment: 
  name: 
   - "base"
  hp:
    rcrop_pad: 4
    cutout_p: 0.5
    cutout_size: 0.5
    ra_p: 1.0
    
  ra:
    space: "ra"
    weight: null
    single: null
    num_op: 2
    magnitude:  14
    random_magnitude: True
    softmax_t: 0.5
    affinity_path: null
    fix_iden: True
    init_epoch: 20
    warmup_ra: False
    aff_calc: False
    aff_model: null

  

dataset:
  name: "cifar10"
  n_class: 10
  img_size: 32
  resized_size: 32
  train_size: null
  mean: 
    - 0.485
    - 0.456
    - 0.406
  std: 
    - 0.229
    - 0.224
    - 0.225
  

optimizer:
  name: SGD
  scheduler:
    name: cosine
    step:
      - 60
      - 120
      - 160
    
  hp:
    lr: 0.1
    lr_min: 0.0001
    warmup_period: null
    warmup_init: 1e-5
    momentum: 0.9
    weight_decay: 5e-4
    

save:
  img: True
  plot: True
  selected: True
  affinity: False
  affinity_all: False
  interval: null

================
File: conf/voc.yaml
================
default:
  env: "cotton"
  seed: 105
  output_dir: "output_cls"
  home_dir: null
  dataset_dir: "/homes/ykohata/code/devml/homes/ypark/code/seg/dataset/voc/VOCdevkit/"
  deterministic: False
  parallel: False
  device_id: 0
  num_workers: 8
  num_excute: 4
  make_dir: True
  add_filename: null


network:
  name: "resnet50"
  pretrained: False
  dropout_rate: 0.3


learn:
  n_epoch: 100
  batch_size: 32


augment: 
  name: 
   - rcrop
  hp:
    rcrop_pad: 237
    # 画像サイズが475なことから
    # min: 475*0.5 = 237.5
    # max: 475*2 = 950
    # maxと元の画像の差: 950-475 = 475
    # 475/2 = 237.5
    # よって237pix

    cutout_p: 0.5
    cutout_size: 0.5
    ra_p: 1.0
    
  ra:
    space: "ra"
    weight: single # 第一段階ではsingle
    single: Contrast # 第一段階では特定のDA選択
    num_op: 2
    magnitude:  14
    random_magnitude: True
    softmax_t: 0.5
    affinity_path: null
    fix_iden: True
    init_epoch: 20
    warmup_ra: False
    aff_calc: False
    aff_model: null

  
dataset:
  name: "voc" 
  n_class: 20
  img_size: 224
  resized_size: 224
  train_size: null
  mean:
    - 0.485
    - 0.456
    - 0.406
  std: 
    - 0.229
    - 0.224
    - 0.225
  ignore_label: 255
  

optimizer:
  name: SGD
  scheduler:
    name: cosine
    step:
      - 60
      - 120
      - 160
    power: 0.9

  loss: 
    name: "ce"
    aux_weight: 0.4
    
  hp:
    lr: 0.01
    lr_min: 0.0001
    warmup_period: null
    warmup_init: 1e-5
    momentum: 0.9
    weight_decay: 1e-4
    
save:
  img: True
  plot: True
  selected: True
  affinity: False
  affinity_all: False
  interval: null

================
File: models/cifar_resnet.py
================
import torch.nn as nn


class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.convs = nn.Sequential(
            nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(planes),
        )
        self.downsample = downsample
        self.relu = nn.ReLU(inplace=True)
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.convs(x)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class Bottleneck(nn.Module):
    expansion = 4
    def __init__(self, in_planes, planes, stride=1, downsample=None):
        super().__init__()
        self.convs = nn.Sequential(
            nn.Conv2d(in_planes, planes, kernel_size=1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(planes),
            nn.ReLU(inplace=True),
            nn.Conv2d(planes, self.expansion * planes, kernel_size=1, bias=False),
            nn.BatchNorm2d(self.expansion * planes),
        )
        self.downsample = downsample
        self.relu = nn.ReLU(inplace=True)
        self.stride = stride

    def forward(self, x):
        residual = x
        out = self.convs(x)
        if self.downsample is not None:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out
    

class ResNetBasicBlock(nn.Module):
    def __init__(self, depth, n_class=10):
        super().__init__()
        # 指定した深さ（畳み込みの層数）でネットワークを構築できるかを確認
        assert (depth - 2) % 6 == 0, 'When use basicblock, depth should be 6n+2 (e.g. 20, 32, 44).'
        n_blocks = (depth - 2) // 6  # 1ブロックあたりのBasic Blockの数を決定

        self.inplanes = 16

        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.relu = nn.ReLU(inplace=True)

        self.layer1 = self._make_layer(16, n_blocks)
        self.layer2 = self._make_layer(32, n_blocks, stride=2)
        self.layer3 = self._make_layer(64, n_blocks, stride=2)

        self.avgpool = nn.AvgPool2d(8)
        self.fc = nn.Linear(64 * BasicBlock.expansion, n_class)

    def _make_layer(self, planes, n_blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * BasicBlock.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * BasicBlock.expansion),
            )

        layers = []
        layers.append(BasicBlock(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * BasicBlock.expansion
        for _ in range(0, n_blocks - 1):
            layers.append(BasicBlock(self.inplanes, planes))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)

        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
    
class ResNetBottleneck(nn.Module):
    def __init__(self, depth, n_class=10):
        super().__init__()
        # 指定した深さ（畳み込みの層数）でネットワークを構築できるかを確認
        assert (depth - 2) % 9 == 0, 'When use Bottleneck, depth should be 9n+2 (e.g. 47, 56, 110, 1199).'
        n_blocks = (depth - 2) // 9  # 1ブロックあたりのBasic Blockの数を決定

        self.inplanes = 16

        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(16)
        self.relu = nn.ReLU(inplace=True)

        self.layer1 = self._make_layer(16, n_blocks)
        self.layer2 = self._make_layer(32, n_blocks, stride=2)
        self.layer3 = self._make_layer(64, n_blocks, stride=2)

        self.avgpool = nn.AvgPool2d(8)
        self.fc = nn.Linear(64 * Bottleneck.expansion, n_class)

    def _make_layer(self, planes, n_blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * Bottleneck.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * Bottleneck.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * Bottleneck.expansion),
            )

        layers = []
        layers.append(Bottleneck(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * Bottleneck.expansion
        for _ in range(0, n_blocks - 1):
            layers.append(Bottleneck(self.inplanes, planes))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)

        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

================
File: models/resnet.py
================
import torch.nn as nn
import math
import torch.utils.model_zoo as model_zoo

__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',
           'resnet152', 'resnet200']

model_urls = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',
    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',
    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',
    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',
}

def conv3x3(in_planes, out_planes, stride=1):
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)


class BasicBlock(nn.Module):
    expansion = 1

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


class Bottleneck(nn.Module):
    expansion = 4

    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super(Bottleneck, self).__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        residual = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            residual = self.downsample(x)

        out += residual
        out = self.relu(out)

        return out


class ResNet(nn.Module):

    def __init__(self, block, layers, num_classes=1000):
        self.inplanes = 64
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        self.avgpool = nn.AvgPool2d(7, stride=1)
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes * block.expansion,
                          kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))
        self.inplanes = planes * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.inplanes, planes))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)

        return x


def resnet18(pretrained=False, **kwargs):
    """Constructs a ResNet-18 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))
    return model


def resnet34(pretrained=False, **kwargs):
    """Constructs a ResNet-34 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))
    return model


def resnet50(pretrained=False, **kwargs):
    """Constructs a ResNet-50 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))
    return model


def resnet101(pretrained=False, **kwargs):
    """Constructs a ResNet-101 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))
    return model


def resnet152(pretrained=False, **kwargs):
    """Constructs a ResNet-152 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)
    if pretrained:
        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))
    return model

def resnet200(pretrained=False, **kwargs):
    """Constructs a ResNet-200 model.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
    """
    model = ResNet(Bottleneck, [3, 24, 36, 3], **kwargs)
    return model

================
File: models/trivial_wide.py
================
import torch
import torch.nn as nn
import torch.nn.init as init
import torch.nn.functional as F
import numpy as np


_bn_momentum = 0.1
CpG = 8


class ExampleWiseBatchNorm2d(nn.BatchNorm2d):
    def __init__(self, num_features, eps=1e-5, momentum=0.1,
                 affine=True, track_running_stats=True):
        super().__init__(num_features, eps, momentum, affine, track_running_stats)

    def forward(self, input):
        self._check_input_dim(input)

        exponential_average_factor = 0.0

        if self.training and self.track_running_stats:
            if self.num_batches_tracked is not None:
                self.num_batches_tracked += 1
                if self.momentum is None:  # use cumulative moving average
                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)
                else:  # use exponential moving average
                    exponential_average_factor = self.momentum

        # calculate running estimates
        if self.training:
            mean = input.mean([0, 2, 3])
            # use biased var in train
            var = input.var([0, 2, 3], unbiased=False)
            n = input.numel() / input.size(1)
            with torch.no_grad():
                self.running_mean = exponential_average_factor * mean\
                    + (1 - exponential_average_factor) * self.running_mean
                # update running_var with unbiased var
                self.running_var = exponential_average_factor * var * n / (n - 1)\
                    + (1 - exponential_average_factor) * self.running_var
            local_means = input.mean([2, 3])
            local_global_means = local_means + (mean.unsqueeze(0) - local_means).detach()
            local_vars = input.var([2, 3], unbiased=False)
            local_global_vars = local_vars + (var.unsqueeze(0) - local_vars).detach()
            input = (input - local_global_means[:,:,None,None]) / (torch.sqrt(local_global_vars[:,:,None,None] + self.eps))
        else:
            mean = self.running_mean
            var = self.running_var
            input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))

        if self.affine:
            input = input * self.weight[None, :, None, None] + self.bias[None, :, None, None]

        return input


class VirtualBatchNorm2d(nn.BatchNorm2d):
    def __init__(self, num_features, eps=1e-5, momentum=0.1,
                 affine=True, track_running_stats=True):
        super().__init__(num_features, eps, momentum, affine, track_running_stats)

    def forward(self, input):
        self._check_input_dim(input)

        exponential_average_factor = 0.0

        if self.training and self.track_running_stats:
            if self.num_batches_tracked is not None:
                self.num_batches_tracked += 1
                if self.momentum is None:  # use cumulative moving average
                    exponential_average_factor = 1.0 / float(self.num_batches_tracked)
                else:  # use exponential moving average
                    exponential_average_factor = self.momentum

        # calculate running estimates
        if self.training:
            mean = input.mean([0, 2, 3])
            # use biased var in train
            var = input.var([0, 2, 3], unbiased=False)
            n = input.numel() / input.size(1)
            with torch.no_grad():
                self.running_mean = exponential_average_factor * mean \
                                    + (1 - exponential_average_factor) * self.running_mean
                # update running_var with unbiased var
                self.running_var = exponential_average_factor * var * n / (n - 1) \
                                   + (1 - exponential_average_factor) * self.running_var
            input = (input - mean.detach()[None, :, None, None]) / (torch.sqrt(var.detach()[None, :, None, None] + self.eps))
        else:
            mean = self.running_mean
            var = self.running_var
            input = (input - mean[None, :, None, None]) / (torch.sqrt(var[None, :, None, None] + self.eps))

        if self.affine:
            input = input * self.weight[None, :, None, None] + self.bias[None, :, None, None]

        return input


def conv3x3(in_planes, out_planes, stride=1):
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)


def conv_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        init.xavier_uniform_(m.weight, gain=np.sqrt(2))
        init.constant_(m.bias, 0)
    elif classname.find('BatchNorm') != -1:
        init.constant_(m.weight, 1)
        init.constant_(m.bias, 0)


class WideBasic(nn.Module):
    def __init__(self, in_planes, planes, dropout_rate, norm_creator, stride=1, adaptive_dropouter_creator=None):
        super(WideBasic, self).__init__()
        self.bn1 = norm_creator(in_planes)
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)
        if adaptive_dropouter_creator is None:
            self.dropout = nn.Dropout(p=dropout_rate)
        else:
            self.dropout = adaptive_dropouter_creator(planes, 3, stride, 1)
        self.bn2 = norm_creator(planes)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != planes:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),
            )

    def forward(self, x):
        out = self.dropout(self.conv1(F.relu(self.bn1(x))))
        out = self.conv2(F.relu(self.bn2(out)))
        out += self.shortcut(x)

        return out


class TrivialWideResNet(nn.Module):
    def __init__(self, depth, widen_factor, dropout_rate, num_classes, adaptive_dropouter_creator, adaptive_conv_dropouter_creator, groupnorm, examplewise_bn, virtual_bn):
        super(TrivialWideResNet, self).__init__()
        self.in_planes = 16
        self.adaptive_conv_dropouter_creator = adaptive_conv_dropouter_creator

        assert ((depth - 4) % 6 == 0), 'Wide-resnet depth should be 6n+4'
        assert sum([groupnorm,examplewise_bn,virtual_bn]) <= 1
        n = int((depth - 4) / 6)
        k = widen_factor

        nStages = [16, 16*k, 32*k, 64*k]

        self.adaptive_dropouters = [] #nn.ModuleList()

        if groupnorm:
            print('Uses group norm.')
            self.norm_creator = lambda c: nn.GroupNorm(max(c//CpG, 1), c)
        elif examplewise_bn:
            print("Uses Example Wise BN")
            self.norm_creator = lambda c: ExampleWiseBatchNorm2d(c, momentum=_bn_momentum)
        elif virtual_bn:
            print("Uses Virtual BN")
            self.norm_creator = lambda c: VirtualBatchNorm2d(c, momentum=_bn_momentum)
        else:
            self.norm_creator = lambda c: nn.BatchNorm2d(c, momentum=_bn_momentum)

        self.conv1 = conv3x3(3, nStages[0])
        self.layer1 = self._wide_layer(WideBasic, nStages[1], n, dropout_rate, stride=1)
        self.layer2 = self._wide_layer(WideBasic, nStages[2], n, dropout_rate, stride=2)
        self.layer3 = self._wide_layer(WideBasic, nStages[3], n, dropout_rate, stride=2)
        self.bn1 = self.norm_creator(nStages[3])
        self.linear = nn.Linear(nStages[3], num_classes)
        if adaptive_dropouter_creator is not None:
            last_dropout = adaptive_dropouter_creator(nStages[3])
        else:
            last_dropout = lambda x: x
        self.adaptive_dropouters.append(last_dropout)

        # self.apply(conv_init)

    def to(self, *args, **kwargs):
        super().to(*args,**kwargs)
        print(*args)
        for ad in self.adaptive_dropouters:
            if hasattr(ad,'to'):
                ad.to(*args,**kwargs)
        return self

    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):
        strides = [stride] + [1]*(num_blocks-1)
        layers = []

        for i,stride in enumerate(strides):
            ada_conv_drop_c = self.adaptive_conv_dropouter_creator if i == 0 else None
            new_block = block(self.in_planes, planes, dropout_rate, self.norm_creator, stride, adaptive_dropouter_creator=ada_conv_drop_c)
            layers.append(new_block)
            if ada_conv_drop_c is not None:
                self.adaptive_dropouters.append(new_block.dropout)

            self.in_planes = planes

        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.conv1(x)
        out = self.layer1(out)
        out = self.layer2(out)
        out = self.layer3(out)
        out = F.relu(self.bn1(out))
        # out = F.avg_pool2d(out, 8)
        out = F.adaptive_avg_pool2d(out, (1, 1))
        out = out.view(out.size(0), -1)
        out = self.adaptive_dropouters[-1](out)
        out = self.linear(out)

        return out

================
File: models/wide_resnet.py
================
import math
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import typing
from numpy import ndarray
from typing import NamedTuple


class BasicBlock(nn.Module):
    def __init__(self, in_ch, out_ch, stride=1, drop_rate=0.3, kernel_size=3):
        super(BasicBlock, self).__init__()
        self.in_is_out = in_ch == out_ch and stride == 1
        self.drop_rate = drop_rate
        self.shortcut = (
            nn.Sequential() if self.in_is_out else nn.Conv2d(in_ch, out_ch, 1, padding=0, stride=stride, bias=False)
        )
        self.bn1 = nn.BatchNorm2d(in_ch)
        self.c1 = nn.Conv2d(in_ch, out_ch, kernel_size, stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_ch)
        self.c2 = nn.Conv2d(out_ch, out_ch, kernel_size, padding=1, bias=False)

    def forward(self, x):
        h = F.relu(self.bn1(x), inplace=True)
        h = self.c1(h)
        h = F.relu(self.bn2(h), inplace=True)
        h = F.dropout(h, p=self.drop_rate, training=self.training)
        h = self.c2(h)
        return h + self.shortcut(x)


class WideResNet(nn.Module):
    def __init__(self, cfg, n_blocks, width_coef):
        super(WideResNet, self).__init__()

        self.num_of_class = cfg.dataset.n_class
        self.n_blocks = n_blocks
        self.n_chs = [16, 16 * width_coef[0], 32 * width_coef[1], 64 * width_coef[2]]

        self.conv1 = nn.Conv2d(3, self.n_chs[0], 3, padding=1, bias=False)
        self.conv2 = self._add_groups(self.n_blocks[0], self.n_chs[0], self.n_chs[1], cfg.network.wide_resnet.dropout_rate1)
        self.conv3 = self._add_groups(
            self.n_blocks[1],
            self.n_chs[1],
            self.n_chs[2],
            cfg.network.wide_resnet.dropout_rate2,
            stride=2,
        )
        self.conv4 = self._add_groups(
            self.n_blocks[2],
            self.n_chs[2],
            self.n_chs[3],
            cfg.network.wide_resnet.dropout_rate3,
            stride=2,
        )
        self.bn = nn.BatchNorm2d(self.n_chs[3])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.full_conn = nn.Linear(self.n_chs[3], self.num_of_class)

        for m in self.modules():  # initialize weights?
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode="fan_out")
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.bias, 0.0)
                nn.init.constant_(m.weight, 1.0)
            elif isinstance(m, nn.Linear):
                nn.init.constant_(m.bias, 0.0)

    def forward(self, h):
        h = self.conv1(h)
        h = self.conv2(h)
        h = self.conv3(h)
        h = self.conv4(h)
        h = F.relu(self.bn(h), inplace=True)
        # h = F.avg_pool2d(h, 8)
        h = self.avgpool(h)
        h = h.view(-1, self.n_chs[3])
        h = self.full_conn(h)

        return F.log_softmax(h, dim=1)

    def _add_groups(self, n_blocks, in_ch, out_ch, drop_rate, stride=1):
        blocks = []

        for _ in range(int(n_blocks)):
            blocks.append(BasicBlock(in_ch, out_ch, stride=stride, drop_rate=drop_rate))

            in_ch, stride = out_ch, 1

        return nn.Sequential(*blocks)

================
File: setup/create_dataset.py
================
import argparse
import datetime
import glob
import os
import pickle
import random
import subprocess
from multiprocessing import Pool

import numpy as np
from PIL import Image

parser = argparse.ArgumentParser(description='aa')
parser.add_argument('--dir', type=str, help='dataset dir')
parser.add_argument('--dataset', type=str, help='cifar10 or cifar100')
args = parser.parse_args()

def download_and_extract_cifar10():
    download_command = "wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
    subprocess.run([download_command], shell=True)

    extract_command = "tar -xf cifar-10-python.tar.gz"
    subprocess.run([extract_command], shell=True)

def download_and_extract_cifar100():
    download_command = "wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz"
    subprocess.run([download_command], shell=True)

    extract_command = "tar -xf cifar-100-python.tar.gz"
    subprocess.run([extract_command], shell=True)


def save_image_parallel_cifar10(pool_list):
    label, data, name, output_dir_path, phase = pool_list

    out_dir = output_dir_path + f"/cifar10/{phase}/{label}"
    os.makedirs(out_dir, exist_ok=True)

    img = data.reshape(3, 32, 32)
    img = np.transpose(img, (1, 2, 0))
    img = Image.fromarray(img)
    img.save(f"{out_dir}/{name.decode('utf-8')}")

def save_image_parallel_cifar100(pool_list):
    label, data, name, output_dir_path, phase = pool_list

    out_dir = output_dir_path + f"/cifar100/{phase}/{label}"
    os.makedirs(out_dir, exist_ok=True)

    img = data.reshape(3, 32, 32)
    img = np.transpose(img, (1, 2, 0))
    img = Image.fromarray(img)
    img.save(f"{out_dir}/{name.decode('utf-8')}")

def save_cifar10_images(output_dir_path, phase):
    # phase: train/test
    if phase == "train":
        file_path_list = [f"{args.dir}/cifar-10-batches-py/data_batch_{idx}" for idx in range(1, 6)]
    elif phase == "test":
        file_path_list = [f"{args.dir}/cifar-10-batches-py/test_batch"]
    else:
        assert "no such phase!"

    pool_list = []
    for path2file in file_path_list:
        with open(path2file, "rb") as f:
            dict_data = pickle.load(f, encoding="bytes")
            for label, data, name in zip(dict_data[b"labels"], dict_data[b"data"], dict_data[b"filenames"]):
                pool_list.append([label, data, name, output_dir_path, phase])
    p = Pool(8)
    p.map(save_image_parallel_cifar10, pool_list)

def save_cifar100_images(output_dir_path, phase):
    # phase: train/test
    if phase == "train":
        file_path_list = [f"{args.dir}/cifar-100-python/train"]
    elif phase == "test":
        file_path_list = [f"{args.dir}/cifar-100-python/test"]
    else:
        assert "no such phase!"

    pool_list = []

    for path2file in file_path_list:
        with open(path2file, "rb") as f:
            dict_data = pickle.load(f, encoding="bytes")
            for key in dict_data:
                print(key)
            for label, data, name in zip(dict_data[b"fine_labels"], dict_data[b"data"], dict_data[b"filenames"]):
                pool_list.append([label, data, name, output_dir_path, phase])
    p = Pool(8)
    p.map(save_image_parallel_cifar100, pool_list)


def split_train_val_parallel(pool_list):
    path2img, class_id, out_dir = pool_list
    command = f"mv {path2img} {out_dir}/{class_id}/"
    subprocess.run([command], shell=True)


def make_val(output_dir_path, name, train_size, val_size):
    print(f"split Train:Val = {train_size}:{val_size}")
    if name == "cifar10":
        n_class = 10
    elif name == "cifar100":
        n_class = 100
    class_train_size = int(np.floor(train_size / n_class))
    class_val_size = int(np.floor(val_size / n_class))
    out_dir = output_dir_path + f"{name}/val"
    os.makedirs(out_dir, exist_ok=True)
    print(len(["train size for a class" for _ in range(class_train_size)]))
    print(len(["val size for a class" for _ in range(class_val_size)]))
    phase_list = ["train" for _ in range(class_train_size)] + ["val" for _ in range(class_val_size)]
    random.shuffle(phase_list)

    pool_list = []
    for class_id in range(n_class):
        os.makedirs(f"{out_dir}/{class_id}/", exist_ok=True)
        img_list = sorted(glob.glob(output_dir_path + f"{name}/train/{class_id}/*.png"))
        count = 0
        for path2img, phase in zip(img_list, phase_list):
            if phase == "val":
                count += 1
                pool_list.append([path2img, class_id, out_dir])
        print(f"for {class_id}, n_val: {count}")
    p = Pool(8)
    p.map(split_train_val_parallel, pool_list)


def save_log(output_dir_path, r_seed, name, train_size, val_size):
    out_path = output_dir_path + f"{name}/log.txt"
    with open(out_path, "w") as f:
        f.write(f"Create: {datetime.datetime.now()}\n")
        f.write(f"Train:val={train_size}:{val_size}, randomseed={r_seed}")


def create_CIFAR10_dataset(output_dir_path, r_seed, val_size):
    train_size = 50000 - val_size
    np.random.seed(r_seed)
    random.seed(r_seed)
    #download_and_extract_cifar10()

    save_cifar10_images(output_dir_path, phase="train")
    save_cifar10_images(output_dir_path, phase="test")
    make_val(output_dir_path, "cifar10" , train_size, val_size)

    save_log(output_dir_path, r_seed, "cifar10", train_size, val_size)


def create_CIFAR100_dataset(output_dir_path, r_seed, val_size):
    train_size = 50000 - val_size
    np.random.seed(r_seed)
    random.seed(r_seed)
    #download_and_extract_cifar100()


    save_cifar100_images(output_dir_path, phase="train")
    save_cifar100_images(output_dir_path, phase="test")
    make_val(output_dir_path, "cifar100", train_size, val_size)

    save_log(output_dir_path, r_seed, "cifar100", train_size, val_size)

output_dir_path = f"{args.dir}/"
print(f"Create {args.dataset} dataset at {args.dir}")
if args.dataset == "cifar10":
    create_CIFAR10_dataset(output_dir_path, 1, 10000)
elif args.dataset == "cifar100":
    create_CIFAR100_dataset(output_dir_path, 1, 10000)

================
File: setup/dataset.sh
================
#!/bin/bash


dataset="cifar10"
HOME_DIR="/homes/ykohata/code/devml/share"
DIR_NAME="dataset"

DATASET_DIR="${HOME_DIR}/${DIR_NAME}"
pwd
mkdir $DATASET_DIR
cd $DATASET_DIR
pwd

if [ "$dataset" == "cifar10" ]; then
    wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
    tar -xzvf cifar-10-python.tar.gz
elif [ "$dataset" == "cifar100" ]; then
    wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz
    tar -xzvf cifar-100-python.tar.gz
else
    echo "Unknown dataset: $dataset, Select [ cifar10 / cifar100 ]"
fi
    

cd $HOME_DIR
python src/setup/create_dataset.py --dir=$DATASET_DIR --dataset=$dataset


# for abci, compress dir. when using, move to $SGE_LOCALDIR
cd $DATASET_DIR
#tar -czvf cifar10.tar.gz cifar10
# tar -czvf cifar100.tar.gz cifar100

================
File: setup/setup_env.sh
================
conda install -y pytorch=2.1.1 torchvision=0.16.1 torchaudio=2.1.1 pytorch-cuda=12.1 -c pytorch -c nvidia

conda install -y numpy=1.26.0
conda install -y pandas
conda install -y matplotlib

pip install omegaconf

================
File: utils/common.py
================
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from pathlib import Path 
import shutil

import torch


def get_time(interval):
    time = {"time" : "{}h {}m {}s".format(
            int(interval / 3600), 
            int((interval % 3600) / 60), 
            int((interval % 3600) % 60))}
    return time


# plot loss and acc curve
def plot_log(cfg, data):
    epochs = np.arange(1, len(data) + 1 - 3)
    fig, ax = plt.subplots(1, 3, figsize=(24, 8), dpi = 80)
    
    ax[0].plot(epochs, data["train_loss"][:-3], label='Train', alpha=0.8, linewidth=5)
    ax[0].plot(epochs, data["val_loss"][:-3], label='Validation', alpha=0.8, linewidth=5)
    ax[0].set_title('Loss', fontsize=30)
    ax[0].set_xlabel('Epochs', fontsize=25)
    ax[0].set_ylabel('Loss', fontsize=25)
    ax[0].legend(bbox_to_anchor=(1, 1), loc="upper right", borderaxespad=0.2, fontsize=30, ncol=1)
    ax[0].tick_params(labelsize=25)
    ax[0].grid()

    ax[1].plot(epochs, data["train_acc"][:-3], label='Training', alpha=0.8, linewidth=5)
    ax[1].plot(epochs, data["val_acc"][:-3], label='Validation', alpha=0.8, linewidth=5)
    ax[1].set_title('Accuracy', fontsize=30)
    ax[1].set_xlabel('Epochs', fontsize=25)
    ax[1].set_ylabel('Accuracy', fontsize=25)
    ax[1].legend(bbox_to_anchor=(1, 0), loc="lower right", borderaxespad=0.2, fontsize=30, ncol=1)
    ax[1].tick_params(labelsize=25)
    ax[1].grid()

    ax[2].plot(epochs, data["val_mAP"][:-3], label='Validation', alpha=0.8, linewidth=5)
    ax[2].set_title('mAP', fontsize=30)
    ax[2].set_xlabel('Epochs', fontsize=25)
    ax[2].set_ylabel('mAP', fontsize=25)
    ax[2].legend(bbox_to_anchor=(1, 0), loc="lower right", borderaxespad=0.2, fontsize=30, ncol=1)
    ax[2].tick_params(labelsize=25)
    ax[2].grid()
    
    fig.suptitle(f"{cfg.out_dir}")
    plt.tight_layout()
    plt.savefig(cfg.out_dir + "graph.png")
    plt.close()


# show sample 12 imgs
def show_img(cfg, dataloader):
    for batched in dataloader:
        images = batched["image"]
        labels = batched["label"]
        break
    
    fig, axes = plt.subplots(3, 4, figsize=(12, 9))
    for i in range(12):
        ax = axes[i // 4, i % 4]
        img = np.transpose(images[i].numpy(), (1, 2, 0))  
        ax.imshow(img)
        ax.set_title(f"Label: {labels[i]}")
        ax.axis('off')

    plt.savefig(cfg.out_dir + "img.png")
    plt.close()



# plot the num of selected method (read from csv file)
def plot_selected(cfg):
    file_path = cfg.out_dir + f"selected_method_{cfg.augment.ra.weight}.csv"

    df = pd.read_csv(file_path)

    fig, ax = plt.subplots(figsize=(16, 9))  

    interval = cfg.learn.n_epoch*10
    if type(cfg.save.interval) == int:
        interval = cfg.save.interval
    for method in df.columns:
        values = df.loc[:, method]
        ax.plot(range(1, len(values)+1, interval), values.iloc[::interval], label=method, marker='o', markersize=2)

    ax.set_xlabel('Iteration', fontsize=25)
    ax.set_ylabel('Count', fontsize=25)
    ax.set_title('Selected method', fontsize=30)
    fig.suptitle(f"{cfg.out_dir}")
    ax.tick_params(labelsize=25)
    ax.legend()
    plt.grid(True)
    plt.savefig(cfg.out_dir + "selected.png")
    plt.close()


def copy_from_sge(cfg, target_dir_name):
    sge_dir = str(Path(cfg.default.dataset_dir).parent)
    files = [f for f in os.listdir(sge_dir) if os.path.isfile(os.path.join(sge_dir, f))]
    for file in files:
        if target_dir_name in file:
            source_path = os.path.join(sge_dir, file)
            destination_path = os.path.join(cfg.out_dir, file)
            shutil.copy2(source_path, destination_path)


def copy_to_sge(cfg, target_path):
    sge_dir = str(Path(cfg.default.dataset_dir).parent)
    shutil.copytree(target_path, sge_dir)


def save_learner(cfg, model, device, BEST=False):
    weight_dir_path = cfg.out_dir + "weights/"
    os.makedirs(weight_dir_path, exist_ok=True)
    if BEST:
        save_file_path = weight_dir_path + "best.pth"
    else:
        save_file_path = weight_dir_path + "latest_epochs.pth"

    torch.save(
        model.to("cpu").state_dict(),
        save_file_path,
    )
    model.to(device)

def save_all_learner(cfg, model, device, epoch):
    weight_dir_path = cfg.out_dir + "weights/"
    os.makedirs(weight_dir_path, exist_ok=True)
    save_file_path = weight_dir_path + f"{epoch}.pth"

    torch.save(
        model.to("cpu").state_dict(),
        save_file_path,
    )
    model.to(device)

def lr_step(cfg, scheduler, epoch):
        if cfg.optimizer.scheduler.name == "warmup":
            scheduler.step(epoch)

        else:
            scheduler.step()

================
File: utils/suggest.py
================
import random
import numpy as np
# from timm.scheduler.cosine_lr import CosineLRScheduler

import torch
import torch.nn as nn
from torchvision.models import vit_b_16, vgg16_bn

from models.cifar_resnet import ResNetBasicBlock, ResNetBottleneck
from models.trivial_wide import TrivialWideResNet
from models.resnet import resnet50


def setup_device(cfg):
    if torch.cuda.is_available():
        device = torch.device(f"cuda:{cfg.default.device_id}")
        
        if not cfg.default.deterministic:
            torch.backends.cudnn.benchmark = True

    else:
        device = "cpu"

    print("CUDA is available:", torch.cuda.is_available())
    print(f"using device: {device}")
    return device


def fixed_r_seed(cfg):
    random.seed(cfg.default.seed)
    np.random.seed(cfg.default.seed)
    torch.manual_seed(cfg.default.seed)
    torch.cuda.manual_seed(cfg.default.seed)
    torch.backends.cudnn.deterministic = True
    torch.use_deterministic_algorithms = True


def suggest_network(cfg):
    if cfg.network.name == "resnet50":
        model = resnet50(pretrained=cfg.network.pretrained)
        model.fc = nn.Linear(model.fc.in_features, cfg.dataset.n_class)

    elif cfg.network.name == "vit":
        model = vit_b_16(weights = "ViT_B_16_Weights.IMAGENET1K_V1")
        model.heads[0] = nn.Linear(model.heads[0].in_features, cfg.dataset.n_class)
  
    elif cfg.network.name == "vgg16":
        model = vgg16_bn()
        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, cfg.dataset.n_class)

    elif cfg.network.name == "resnet56":
        # 'When use Bottleneck, depth should be 9n+2 (e.g. 47, 56, 110, 1199).'
        model = ResNetBottleneck(depth=56, n_class=cfg.dataset.n_class)    # BasicBlock構造を用いる場合

    # 'When use basicblock, depth should be 6n+2 (e.g. 20, 32, 44).'
    elif cfg.network.name == "resnet20":
        model = ResNetBasicBlock(depth=20, n_class=cfg.dataset.n_class)   # Bottleneck構造を用いる場合

    elif cfg.network.name == 'wrn28_10':
        model = TrivialWideResNet(
            28, 10, 
            dropout_rate=cfg.network.dropout_rate, 
            num_classes=cfg.dataset.n_class, 
            adaptive_dropouter_creator=None,
            adaptive_conv_dropouter_creator=None, 
            groupnorm=False, 
            examplewise_bn=False, 
            virtual_bn=False
            )
        
    return model


def suggest_optimizer(cfg, model):
    if cfg.optimizer.name == "SGD":
        optimizer = torch.optim.SGD(
            params=model.parameters(), 
            lr=cfg.optimizer.hp.lr, 
            momentum=cfg.optimizer.hp.momentum, 
            weight_decay=cfg.optimizer.hp.weight_decay, 
            nesterov=True,
        )
    elif cfg.optimizer.name == "AdamW":
        optimizer = torch.optim.AdamW(
            params=model.parameters(),
            lr = cfg.optimizer.hp.lr,
            weight_decay=cfg.optimizer.hp.weight_decay,
        )
    elif cfg.optimizer.name == "Adam":
        optimizer = torch.optim.Adam(
            params=model.parameters(),
            lr = cfg.optimizer.hp.lr,
            weight_decay=cfg.optimizer.hp.weight_decay,
        )
        
    else:
        raise ValueError(f"Invalid optimizer ... {cfg.optimizer.name}, Select from < SGE, Adam >.")
    
    return optimizer


def suggest_scheduler(cfg, optimizer):
    if cfg.optimizer.scheduler.name == "fix":
        scheduler = torch.optim.lr_scheduler.MultiStepLR(
            optimizer,
            milestones=[],
            gamma=1.0,
        )

    elif cfg.optimizer.scheduler.name == "cosine":
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=cfg.learn.n_epoch,
            eta_min=cfg.optimizer.hp.lr_min,
        )

    elif cfg.optimizer.scheduler.name == "step":
        scheduler = torch.optim.lr_scheduler.MultiStepLR(
            optimizer,
            milestones=cfg.optimizer.scheduler.step,
            gamma=0.1,
        )
        
    # elif cfg.optimizer.scheduler.name == "warmup":
    #     scheduler = CosineLRScheduler(
    #         optimizer,
    #         t_initial=cfg.learn.n_epoch,
    #         lr_min=cfg.optimizer.hp.lr_min, 
    #         warmup_t=cfg.optimizer.hp.warmup_period,
    #         warmup_lr_init=cfg.optimizer.hp.warmup_init,
    #         warmup_prefix=False
    #         )
    
    else:
        raise ValueError(f"Invalid Lr Scheduler ... {cfg.optimizer.scheduler.name}, select from < cosine, step >")
    
    return scheduler


def suggest_loss_func():
    return nn.BCEWithLogitsLoss(reduction='sum')

================
File: scripts/abci/test.sh
================
#!/bin/bash
#$ -l rt_G.small=1
#$ -l h_rt=6:00:00
#$ -j y
#$ -o /groups/gaa50073/park-yuna/kd/comi/out0613/cifar100/
#$ -cwd

source /etc/profile.d/modules.sh
module load  python/3.11/3.11.9
source ~/.bashrc
conda activate new

WORKDIR="/groups/gaa50073/park-yuna/share/src/"
echo "ok"

mkdir -p $SGE_LOCALDIR/datasets
cp -v "/groups/gaa50073/park-yuna/datasets/cifar10.tar.gz" $SGE_LOCALDIR/datasets/
# cp -v "/groups/gaa50073/park-yuna/datasets/cifar100.tar.gz" $SGE_LOCALDIR/datasets/
cd $SGE_LOCALDIR/datasets
tar -I pigz -xf "cifar10.tar.gz"
# tar -I pigz -xf "cifar100.tar.gz"
ls

cd $WORKDIR

seed=501

python main.py cifar10 \
    default.dataset_dir="$SGE_LOCALDIR/datasets/" \
    default.seed=$seed \
    augment.name=["ra"] \
    augment.ra.weight="affinity" \
    learn.n_epoch=4 \
    augment.ra.aff_calc=True \
    augment.ra.aff_model="/groups/gaa50073/park-yuna/share/output/seed501/cifar10/SinglePass0.5_2_Randmag/weights/best.pth"

================
File: scripts/cotton/test.sh
================
#!/bin/bash
#$ -j 
#$ -o /homes/ykohata/code/devml/homes/ypark/code/seg/trash/
#$ -cwd

source /etc/profile.d/modules.sh
module load  python/3.11/3.11.2
source ~/.bashrc
conda activate new-ra

WORKDIR="/homes/ykohata/code/devml/homes/ypark/code/seg/src_cls/src"
echo "ok"

cd $WORKDIR



seed=111
python main.py  voc \
    default.seed=$seed \
    augment.name=["hflip","rcrop","cutout"] \
    learn.n_epoch=3 \
    augment.hp.cutout_p=1.0 \
    augment.hp.rcrop_pad=14

================
File: Noneoutput_cls/seed111/voc/HflipRcropCutout/config.yaml
================
default:
  env: cotton
  seed: 111
  output_dir: output_cls
  home_dir: null
  dataset_dir: /homes/ykohata/code/devml/homes/ypark/code/seg/dataset/voc/VOCdevkit/
  deterministic: false
  parallel: false
  device_id: 0
  num_workers: 8
  num_excute: 4
  make_dir: true
  add_filename: null
network:
  name: resnet50
  pretrained: false
  dropout_rate: 0.3
learn:
  n_epoch: 3
  batch_size: 32
augment:
  name:
  - hflip
  - rcrop
  - cutout
  hp:
    rcrop_pad: 14
    cutout_p: 1.0
    cutout_size: 0.5
    ra_p: 1.0
  ra:
    space: ra
    weight: single
    single: Contrast
    num_op: 2
    magnitude: 14
    random_magnitude: true
    softmax_t: 0.5
    affinity_path: null
    fix_iden: true
    init_epoch: 20
    warmup_ra: false
    aff_calc: false
    aff_model: null
dataset:
  name: voc
  n_class: 20
  img_size: 224
  resized_size: 224
  train_size: null
  mean:
  - 0.485
  - 0.456
  - 0.406
  std:
  - 0.229
  - 0.224
  - 0.225
  ignore_label: 255
optimizer:
  name: SGD
  scheduler:
    name: cosine
    step:
    - 60
    - 120
    - 160
    power: 0.9
  loss:
    name: ce
    aux_weight: 0.4
  hp:
    lr: 0.01
    lr_min: 0.0001
    warmup_period: null
    warmup_init: 1.0e-05
    momentum: 0.9
    weight_decay: 0.0001
save:
  img: true
  plot: true
  selected: true
  affinity: false
  affinity_all: false
  interval: null
out_dir: Noneoutput_cls/seed111/voc/HflipRcropCutout/
execute_config_name: voc
override_cmd:
- default.seed=111
- augment.name=[hflip,rcrop,cutout]
- learn.n_epoch=3
- augment.hp.cutout_p=1.0
- augment.hp.rcrop_pad=14
datetime: '2024-07-31 03:53:54.398004'
